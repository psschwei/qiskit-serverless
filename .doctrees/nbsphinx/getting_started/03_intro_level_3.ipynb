{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73944cc6-e22d-43ae-8716-78bb00360a0f",
   "metadata": {},
   "source": [
    "# Getting started - level 3\n",
    "\n",
    "In this tutorial we will explore a little bit more advanced example of a program that require some configuration, requirements setup, etc. \n",
    "\n",
    "Again we will start with writing code for our program and saving it to [./source_files/gs_level_3.py](./source_files/gs_level_3.py) file.\n",
    "This time, our program will run an estimator as a parallel function, computing the expectation value of a single observable over a set of random circuits. The results will be saved to a database, which means it will be stored in a formatted way and later on we can fetch results of or programs without looking at logs.\n",
    "\n",
    "```python\n",
    "# source_files/gs_level_3.py\n",
    "\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.circuit.random import random_circuit\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit.primitives import Estimator\n",
    "\n",
    "from quantum_serverless import QuantumServerless, ditribute_task, get, put, save_result\n",
    "\n",
    "# 1. let's annotate out function to convert it\n",
    "# to function that can be executed remotely\n",
    "# using `ditribute_task` decorator\n",
    "@ditribute_task()\n",
    "def my_function(circuit: QuantumCircuit, obs: SparsePauliOp):\n",
    "    \"\"\"Compute expectation value of an obs given a circuit\"\"\"\n",
    "    return Estimator().run([circuit], [obs]).result().values\n",
    "\n",
    "\n",
    "# 2. Next let's create our serverless object that we will be using to create context\n",
    "# which will allow us to run functions in parallel\n",
    "serverless = QuantumServerless()\n",
    "\n",
    "circuits = [random_circuit(2, 2) for _ in range(3)]\n",
    "\n",
    "# 3. create serverless context which will allow us to run functions in parallel\n",
    "with serverless.context():\n",
    "    # 4. The observable is the same for all expectation value calculations. So we can put that object into remote storage since it will be shared among all executions of my_function.\n",
    "    obs_ref = put(SparsePauliOp([\"ZZ\"]))\n",
    "\n",
    "    # 5. we can run our function for a single input circuit \n",
    "    # and get back a reference to it as now our function is a remote one\n",
    "    function_reference = my_function(circuits[0], obs_ref)\n",
    "\n",
    "    # 5.1 or we can run N of them in parallel (for all circuits)\n",
    "    # note: if we will be using real backends (QPUs) we should either use\n",
    "    #       N separate backends to run them in parallel or\n",
    "    #       one will be running after each other sequentially\n",
    "    function_references = [my_function(circ, obs_ref) for circ in circuits]\n",
    "\n",
    "    # 6. to get results back from reference\n",
    "    # we need to call `get` on function reference\n",
    "    single_result = get(function_reference)\n",
    "    parallel_result = get(function_references)\n",
    "    print(\"Single execution:\", single_result)\n",
    "    print(\"N parallel executions:\", parallel_result)\n",
    "\n",
    "    # 6.1 (Optional) write results to db.\n",
    "    save_result({\n",
    "        \"status\": \"ok\",\n",
    "        \"single\": single_result.tolist(),\n",
    "        \"parallel_result\": [entry.tolist() for entry in parallel_result]\n",
    "    })\n",
    "\n",
    "```\n",
    "\n",
    "As you can see we move to advanced section of using serverless. \n",
    "\n",
    "Here we are using `ditribute_task` decorator to convert our function to asynchronous distributed one. \n",
    "With that `my_function` is converted into asynchronous distributed function (as a result you will be getting function pointer), which means that the function no longer executes as part of your local python process, but executed on configured compute resources.\n",
    "\n",
    "Moreover, we are using `save_result` function in order to save results into database storage, so we can retrieve it later after program execution.\n",
    "\n",
    "Next we need to run this program. For that we need to import necessary modules and configure QuantumServerless client. We are doing so by providing name and host for deployed infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9130c64a-1e7f-4d08-afff-b2905b2d95ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from quantum_serverless import QuantumServerless, GatewayProvider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f22daae-9f0e-4f7a-8a1f-5ade989d8be9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<QuantumServerless | providers [gateway-provider]>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "provider = GatewayProvider(\n",
    "    username=\"user\", # this username has already been defined in local docker setup and does not need to be changed\n",
    "    password=\"password123\", # this password has already been defined in local docker setup and does not need to be changed\n",
    "    host=\"http://gateway:8000\", # address of provider\n",
    ")\n",
    "\n",
    "serverless = QuantumServerless(provider)\n",
    "serverless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3321b4a0-b60d-433a-992a-79e5868d309b",
   "metadata": {},
   "source": [
    "Run program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f556dd85-35da-48d1-9ae1-f04a386544d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Job | 65dadf22-16d5-40e2-9a3e-de460e439c34>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from quantum_serverless import Program \n",
    "\n",
    "program = Program(\n",
    "    title=\"Advanced program\",\n",
    "    entrypoint=\"gs_level_3.py\",\n",
    "    working_dir=\"./source_files/\"\n",
    ")\n",
    "\n",
    "job = serverless.run_program(program)\n",
    "job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2de3fd64-9010-48d9-ac7c-f46a7b36ba81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCEEDED'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29336f0b-ffcf-4cdb-931c-11faf09f15ff",
   "metadata": {},
   "source": [
    "With `job.result()` we can get saved results inside of our function back. `.result()` call will return you whatever you passed in `save_result` inside the program file, while `.logs()` will return everything that was logged by job (stdio, e.g prints)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fb8931f-c8e2-49dd-923f-16fa3a7a5feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"status\": \"ok\", \"single\": [1.0], \"parallel_result\": [[1.0], [1.0], [1.0]]}'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job.result()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
